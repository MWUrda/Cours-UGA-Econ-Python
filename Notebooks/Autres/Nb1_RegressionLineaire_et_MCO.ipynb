{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> Régression Linéaire et Moindres Carrés</center>\n",
    "#### <center>Michal Urdanivia (UGA)</center>\n",
    "#### <center> michal.wong-urdanivia@univ-grenoble-alpes.fr </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Références\n",
    "\n",
    "En ce qui concerne l'utilisation de Python pour le travail empirique nous ne pourrons pas aller au-delà de ce que nous utilisons dans le cours. Pour vous former sur ce langage et son utilisation dans le travail empirique vous pouvez consulter:\n",
    "\n",
    "* Le site [QuantEcon](https://quantecon.org/), en particulier les \"lectures\" en [\"Data Science\"](https://datascience.quantecon.org/)\n",
    "\n",
    "* Le site que [Jake VanderPlas](https://jakevdp.github.io/pages/about.html) dédie à son [ouvrage sur Python en Data Science](https://jakevdp.github.io/PythonDataScienceHandbook/).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>  Données d'application </center>\n",
    "\n",
    "Nous allons utiliser des données qui sont disponible sur le site que [Bruce Hansen](https://www.ssc.wisc.edu/~bhansen/) dédie à son cours d'[économétrie](https://www.ssc.wisc.edu/~bhansen/econometrics/). Plus précisément, nous allons utiliser des données extraites du **Current Population Survey**(CPS) de 2009. Une description du fichier est [ici](https://www.ssc.wisc.edu/~bhansen/econometrics/cps09mar_description.pdf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lecture des données\n",
    "\n",
    "Pour travailler(e.g., lire/charger les données, sélectionner des variables, etc) sur les données nous allons utiliser la bibliothèque [pandas](https://fr.wikipedia.org/wiki/Pandas) dont vous n'avez pas besoin de lire toute la documentation pour l'utiliser(quelqu'un a t-il déjà lu les quelques 3000 pages correspondantes à la doc en pdf? ou au moins 50 %?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import/appel de la bibliothèque pandas et autres qui seront utilisées \n",
    "# Remarques: \n",
    "# - les écritures après le \"#\" sont des commentaires non considérés comme du code à executer.\n",
    "# - pd, np, etc ci-après sont des abréviations que nous donnons aux bibliothèques correspondates\n",
    "# (elle sont courantes comme vous pourrez le constater en regardant un peu sur le web)\n",
    "\n",
    "\n",
    "import pandas as pd   \n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 50742 entries, 0 to 50741\n",
      "Data columns (total 12 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   age        50742 non-null  float64\n",
      " 1   female     50742 non-null  float64\n",
      " 2   hisp       50742 non-null  float64\n",
      " 3   education  50742 non-null  float64\n",
      " 4   earnings   50742 non-null  float64\n",
      " 5   hours      50742 non-null  float64\n",
      " 6   week       50742 non-null  float64\n",
      " 7   union      50742 non-null  float64\n",
      " 8   uncov      50742 non-null  float64\n",
      " 9   region     50742 non-null  float64\n",
      " 10  race       50742 non-null  float64\n",
      " 11  marital    50742 non-null  float64\n",
      "dtypes: float64(12)\n",
      "memory usage: 5.0 MB\n"
     ]
    }
   ],
   "source": [
    "# Lecture des données.\n",
    "# On utilise la fonction \"read_stata\" dans pandas pour lire le fichier au format stata(\".dta\") disponible \n",
    "# sur le site de Bruce Hansen. Vous pouvez aussi le télécharger sur votre poste et ensuite le lire.\n",
    "# Nous l'appellons cps_df(pour cps data frame)\n",
    "\n",
    "cps_df = pd.read_stata(\"https://www.ssc.wisc.edu/~bhansen/econometrics/cps09mar.dta\")\n",
    "cps_df.info()   # Affichage d'informations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age  female  hisp  education  earnings  hours  week  union  uncov  region  \\\n",
      "0  52.0     0.0   0.0       12.0  146000.0   45.0  52.0    0.0    0.0     1.0   \n",
      "1  38.0     0.0   0.0       18.0   50000.0   45.0  52.0    0.0    0.0     1.0   \n",
      "2  38.0     0.0   0.0       14.0   32000.0   40.0  51.0    0.0    0.0     1.0   \n",
      "3  41.0     1.0   0.0       13.0   47000.0   40.0  52.0    0.0    0.0     1.0   \n",
      "4  42.0     0.0   0.0       13.0  161525.0   50.0  52.0    1.0    0.0     1.0   \n",
      "\n",
      "   race  marital  \n",
      "0   1.0      1.0  \n",
      "1   1.0      1.0  \n",
      "2   1.0      1.0  \n",
      "3   1.0      1.0  \n",
      "4   1.0      1.0  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>female</th>\n",
       "      <th>hisp</th>\n",
       "      <th>education</th>\n",
       "      <th>earnings</th>\n",
       "      <th>hours</th>\n",
       "      <th>week</th>\n",
       "      <th>union</th>\n",
       "      <th>uncov</th>\n",
       "      <th>region</th>\n",
       "      <th>race</th>\n",
       "      <th>marital</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50742.000000</td>\n",
       "      <td>50742.000000</td>\n",
       "      <td>50742.000000</td>\n",
       "      <td>50742.000000</td>\n",
       "      <td>50742.000000</td>\n",
       "      <td>50742.000000</td>\n",
       "      <td>50742.000000</td>\n",
       "      <td>50742.000000</td>\n",
       "      <td>50742.000000</td>\n",
       "      <td>50742.000000</td>\n",
       "      <td>50742.000000</td>\n",
       "      <td>50742.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>42.131725</td>\n",
       "      <td>0.425722</td>\n",
       "      <td>0.148792</td>\n",
       "      <td>13.924619</td>\n",
       "      <td>55091.530685</td>\n",
       "      <td>43.827244</td>\n",
       "      <td>51.879272</td>\n",
       "      <td>0.021521</td>\n",
       "      <td>0.002207</td>\n",
       "      <td>2.635627</td>\n",
       "      <td>1.433507</td>\n",
       "      <td>2.763174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.487620</td>\n",
       "      <td>0.494457</td>\n",
       "      <td>0.355887</td>\n",
       "      <td>2.744447</td>\n",
       "      <td>52222.071166</td>\n",
       "      <td>7.704467</td>\n",
       "      <td>0.598646</td>\n",
       "      <td>0.145113</td>\n",
       "      <td>0.046930</td>\n",
       "      <td>1.060051</td>\n",
       "      <td>1.317430</td>\n",
       "      <td>2.503158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>33.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>28000.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>65000.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>85.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>561087.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        female          hisp     education       earnings  \\\n",
       "count  50742.000000  50742.000000  50742.000000  50742.000000   50742.000000   \n",
       "mean      42.131725      0.425722      0.148792     13.924619   55091.530685   \n",
       "std       11.487620      0.494457      0.355887      2.744447   52222.071166   \n",
       "min       15.000000      0.000000      0.000000      0.000000       1.000000   \n",
       "25%       33.000000      0.000000      0.000000     12.000000   28000.000000   \n",
       "50%       42.000000      0.000000      0.000000     13.000000   42000.000000   \n",
       "75%       51.000000      1.000000      0.000000     16.000000   65000.000000   \n",
       "max       85.000000      1.000000      1.000000     20.000000  561087.000000   \n",
       "\n",
       "              hours          week         union         uncov        region  \\\n",
       "count  50742.000000  50742.000000  50742.000000  50742.000000  50742.000000   \n",
       "mean      43.827244     51.879272      0.021521      0.002207      2.635627   \n",
       "std        7.704467      0.598646      0.145113      0.046930      1.060051   \n",
       "min       36.000000     48.000000      0.000000      0.000000      1.000000   \n",
       "25%       40.000000     52.000000      0.000000      0.000000      2.000000   \n",
       "50%       40.000000     52.000000      0.000000      0.000000      3.000000   \n",
       "75%       45.000000     52.000000      0.000000      0.000000      4.000000   \n",
       "max       99.000000     52.000000      1.000000      1.000000      4.000000   \n",
       "\n",
       "               race       marital  \n",
       "count  50742.000000  50742.000000  \n",
       "mean       1.433507      2.763174  \n",
       "std        1.317430      2.503158  \n",
       "min        1.000000      1.000000  \n",
       "25%        1.000000      1.000000  \n",
       "50%        1.000000      1.000000  \n",
       "75%        1.000000      5.000000  \n",
       "max       21.000000      7.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Affichage des premières lignes(5 par défaut) et de statistiques descriptives de base(moyennes, écart-types, etc)\n",
    "print(cps_df.head())\n",
    "cps_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>  Régression linéaire et estimation par MCO </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle que nous allons estimer suppose que,\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "Y &= X^\\top \\beta + U, \\tag{1}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "où $ Y\\in \\mathbb{R} $, $ X\\in\\mathbb{R}^K $, $ U\\in \\mathbb{R} $, sont de variables aléatoires: $ Y $ est la variables dépendante, \n",
    "$ X $ sont $ K $ régresseurs, $ U $ est l'erreur du modèle. $ Y $ et $ X $ sont observables tandis que $ U $ représente tout ce qui peut faire varier $ Y $ pour des valeurs données de $ X $. $ \\beta \\in \\mathbb{R}^K $ sont les paramètres inconnus du modèle qu'on se propose d'estimer car ils permettent de mesurer la relation entre les éléments de $ X $ et $ Y $ sans pour autant que cette relation si elle existe puisse avoir une interprétation causale ou en termers de modèle de régression. \n",
    "\n",
    "En effet, pour que $ \\beta $ dans (1) soit un vecteur de paramètres d'un modèle de régression linéaire, à savoir d'un modèle tel que\n",
    " $ \\operatorname{E}(Y|X) = X^\\top \\beta $, on doit supposer que $ \\operatorname{E}(U|X) = 0 $. En particulier, c'est sous cette condition(ainsi que d'autres vues en cours) que l'estimateur des MCO de $ \\beta $ sera sans biais et convergent. Notons néanmoins que la convergence peut être obtenue  en replaçant  la condition d'**exogénéité forte** $ \\operatorname{E}(U|X) = 0$ par celle **exogénéité faible** $ \\operatorname{E}(XU) = 0$(mais dans ce cas l'estimateur des MCO n'est plus sans biais).\n",
    "\n",
    "Pour estimer $ \\beta $ on s'appuie sur des données de $ (Y, X) $ qu'on suppose i.i.d. $ \\{(Y_i, X_i)\\}_{i=1}^n $ et ainsi,\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "Y_i &= X_i^\\top \\beta + U_i, \\ i=1, \\ldots, n. \\tag{2}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "L'estimateur des MCO de $ \\beta $ est alors défini par,\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\hat{\\beta}_n^{MCO} &=  \\argmin_{b\\in \\mathbb{R}^K} n^{-1}\\sum_{i=1}^n(Y_i - X_i^\\top b)^2 \\tag{3}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "et les conditions du premier ordre, \n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "n^{-1}\\sum_{i=1}^n X_i(Y_i - X_i^\\top b) &=0,\n",
    "\\end{align*}\n",
    "$$\n",
    "permettent de calculer $ \\hat{\\beta}_n^{MCO} $ dès lors que $ n^{-1}\\sum_{i=1}^n X_iX_i^\\top $ est de plein rang ce qui revient à l'absence de multicolinéarité entre régrésseurs dans l'échantillon. On obtient alors,\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\hat{\\beta}_n^{MCO} &= \\left( n^{-1}\\sum_{i=1}^n X_iX_i^\\top \\right)^{-1} n^{-1}\\sum_{i=1}^n X_iY_i \\tag{4}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "On peut alors définir $\\hat{U}_i = Y_i -X_i^\\top\\hat{\\beta}_n^{MCO}$ avec $\\hat{\\beta}_n^{MCO}$ donné par (4) et écrire la décomposition\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "Y_i &= X_i^\\top\\hat{\\beta}_n^{MCO} + \\hat{U}_i, \\ \\ n^{-1}\\sum_{i=1}^n X_i\\hat{U}_i = 0. \\tag{5}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "\n",
    "Notons que le facteur \"$ n^{-1} $\"  dans (3) souligne que la que la fonction objectif pour obtenir l'estimateur des MCO est la contrepartie empirique de celle dans le problème,\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\beta &=  \\argmin_{b\\in \\mathbb{R}^K}\\operatorname{E}\\left((Y_i - X_i^\\top b)^2\\right) \\tag{6}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "qui a pour conditions du premier ordre,\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\operatorname{E}\\left(X_i(Y_i - X_i^\\top b) \\right) &=0,\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "et à condition que $ \\operatorname{E}(X_iX_i^\\top) $ soit de plein rang ce qui revient à l'absence de multicolinéarité entre régrésseurs dans la population théorique, on obtient,\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\beta &= \\left( \\operatorname{E}(X_iX_i^\\top) \\right)^{-1} \\operatorname{E}(X_iY_i) \\tag{7}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "On peut alors définir $U_i = Y_i- X_i^\\top\\beta$ avec $\\beta$ donné par (7) et écrire la décomposition\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "Y_i &= X_i^\\top\\beta + U_i, \\ \\  \\operatorname{E}(X_iU_i) = 0. \\tag{8}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "\n",
    "Donc $ \\hat{\\beta}_n^{MCO} $ peut être calculé indépendamment des conditions faites sur la relation entre $ X $ et $ U $ dans (1)(à condition de les éléments de $ X_i $ ne soient pas colinéaires dans l'échantillon). L'importance de ces conditions tient au propriétés qu'elles permettent d'établir(e.g., convergence, absence de biais) et aux interprétations(e.g., estimation des paramètres d'un modèle de régression). \n",
    "En particulier:\n",
    "\n",
    "- Avec la condition $ \\operatorname{E}(U_i|X_i) = 0 $, l'estimateur des MCO est celui des paramètres d'un modèle de régression linéaire, à savoir tel que (2) et $ \\operatorname{E}(Y_i|X_i) = X_i^\\top\\beta $. Cet estimateur est convergent, et sans biais.\n",
    "\n",
    "- Avec la condition $ \\operatorname{E}(X_iU_i) = 0 $ l'estimateur des MCO est celui des paramètres d'un modèle tel que (8). C'est ce qu'on appelle un estimateur les paramètres de la projection de $ Y_i $ sur $ X_i $.  Cet estimateur est seulement convergent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Application.\n",
    "\n",
    "Nous allons considérer un modèle où la variable dépendante est un log du salaire, et les régresseurs incluent une constante, le niveau d'études, une mesure de l'expérience en années, son carré, une indicatrice du sexe, et une indicatrice d'être noir.  Soit,\n",
    "\n",
    "- $ Y $: $ lwage $,\n",
    "- $ X $: $ (1, educ, exper, expersq, female, black)$.\n",
    "\n",
    "Nous allons utiliser un échantillon qui correspond aux personnes qui se définissent comme blanches, ou noires(remarque: la collecte de données américaines permet de recueillir des informations quant à l'appartenance à des groupes ethniques préalablement définis). Certaines des variables utilisés doivent d'abord être calculées.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46411, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>female</th>\n",
       "      <th>hisp</th>\n",
       "      <th>education</th>\n",
       "      <th>earnings</th>\n",
       "      <th>hours</th>\n",
       "      <th>week</th>\n",
       "      <th>union</th>\n",
       "      <th>uncov</th>\n",
       "      <th>region</th>\n",
       "      <th>marital</th>\n",
       "      <th>exper</th>\n",
       "      <th>expersq</th>\n",
       "      <th>lwage</th>\n",
       "      <th>white</th>\n",
       "      <th>black</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>46411.000000</td>\n",
       "      <td>46411.000000</td>\n",
       "      <td>46411.000000</td>\n",
       "      <td>46411.000000</td>\n",
       "      <td>46411.000000</td>\n",
       "      <td>46411.000000</td>\n",
       "      <td>46411.000000</td>\n",
       "      <td>46411.000000</td>\n",
       "      <td>46411.000000</td>\n",
       "      <td>46411.000000</td>\n",
       "      <td>46411.000000</td>\n",
       "      <td>46411.000000</td>\n",
       "      <td>46411.000000</td>\n",
       "      <td>46411.000000</td>\n",
       "      <td>46411.000000</td>\n",
       "      <td>46411.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>42.213915</td>\n",
       "      <td>0.423477</td>\n",
       "      <td>0.154468</td>\n",
       "      <td>13.882269</td>\n",
       "      <td>55082.729181</td>\n",
       "      <td>43.879964</td>\n",
       "      <td>51.879554</td>\n",
       "      <td>0.021934</td>\n",
       "      <td>0.002262</td>\n",
       "      <td>2.597789</td>\n",
       "      <td>2.754584</td>\n",
       "      <td>22.331646</td>\n",
       "      <td>6.337939</td>\n",
       "      <td>2.945706</td>\n",
       "      <td>0.889358</td>\n",
       "      <td>0.110642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.468616</td>\n",
       "      <td>0.494115</td>\n",
       "      <td>0.361400</td>\n",
       "      <td>2.713667</td>\n",
       "      <td>52324.915589</td>\n",
       "      <td>7.701222</td>\n",
       "      <td>0.596815</td>\n",
       "      <td>0.146471</td>\n",
       "      <td>0.047511</td>\n",
       "      <td>1.047513</td>\n",
       "      <td>2.497897</td>\n",
       "      <td>11.623014</td>\n",
       "      <td>5.635276</td>\n",
       "      <td>0.673137</td>\n",
       "      <td>0.313692</td>\n",
       "      <td>0.313692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-7.863267</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>33.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>28000.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.690000</td>\n",
       "      <td>2.560096</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>4.840000</td>\n",
       "      <td>2.956512</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>65000.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>9.610000</td>\n",
       "      <td>3.354542</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>85.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>561087.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>56.250000</td>\n",
       "      <td>5.583706</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        female          hisp     education       earnings  \\\n",
       "count  46411.000000  46411.000000  46411.000000  46411.000000   46411.000000   \n",
       "mean      42.213915      0.423477      0.154468     13.882269   55082.729181   \n",
       "std       11.468616      0.494115      0.361400      2.713667   52324.915589   \n",
       "min       15.000000      0.000000      0.000000      0.000000       1.000000   \n",
       "25%       33.000000      0.000000      0.000000     12.000000   28000.000000   \n",
       "50%       42.000000      0.000000      0.000000     13.000000   42000.000000   \n",
       "75%       51.000000      1.000000      0.000000     16.000000   65000.000000   \n",
       "max       85.000000      1.000000      1.000000     20.000000  561087.000000   \n",
       "\n",
       "              hours          week         union         uncov        region  \\\n",
       "count  46411.000000  46411.000000  46411.000000  46411.000000  46411.000000   \n",
       "mean      43.879964     51.879554      0.021934      0.002262      2.597789   \n",
       "std        7.701222      0.596815      0.146471      0.047511      1.047513   \n",
       "min       36.000000     48.000000      0.000000      0.000000      1.000000   \n",
       "25%       40.000000     52.000000      0.000000      0.000000      2.000000   \n",
       "50%       40.000000     52.000000      0.000000      0.000000      3.000000   \n",
       "75%       45.000000     52.000000      0.000000      0.000000      3.000000   \n",
       "max       99.000000     52.000000      1.000000      1.000000      4.000000   \n",
       "\n",
       "            marital         exper       expersq         lwage         white  \\\n",
       "count  46411.000000  46411.000000  46411.000000  46411.000000  46411.000000   \n",
       "mean       2.754584     22.331646      6.337939      2.945706      0.889358   \n",
       "std        2.497897     11.623014      5.635276      0.673137      0.313692   \n",
       "min        1.000000     -4.000000      0.000000     -7.863267      0.000000   \n",
       "25%        1.000000     13.000000      1.690000      2.560096      1.000000   \n",
       "50%        1.000000     22.000000      4.840000      2.956512      1.000000   \n",
       "75%        5.000000     31.000000      9.610000      3.354542      1.000000   \n",
       "max        7.000000     75.000000     56.250000      5.583706      1.000000   \n",
       "\n",
       "              black  \n",
       "count  46411.000000  \n",
       "mean       0.110642  \n",
       "std        0.313692  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Échantillon\n",
    "\n",
    "cps_df2 = cps_df[(cps_df.race == 1.0) | (cps_df.race == 2.0)]\n",
    "\n",
    "# Variables\n",
    "\n",
    "cps_df2 = cps_df2.assign(exper = cps_df2.age - cps_df2.education - 6) # Expérience\n",
    "cps_df2 = cps_df2.assign(expersq = cps_df2.exper**2/100) # Expérience au carré\n",
    "cps_df2 = cps_df2.assign(lwage = np.log(cps_df2.earnings / ( cps_df2.hours * cps_df2.week))) # revenu horaire\n",
    "cps_df2 = pd.get_dummies(data = cps_df2, columns= ['race']) # indicatrice d'appartenance ethnique\n",
    "cps_df2 = cps_df2.rename(columns={\"race_1.0\": \"white\", \"race_2.0\": \"black\"}) # on les renomme \n",
    "print(cps_df2.shape)\n",
    "cps_df2.describe()\n",
    "#cps_df2[['exper', 'age', 'education', 'expersq', 'lwage', 'earnings', 'week', 'hours']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calcul avec modules existants.\n",
    "\n",
    "En général pour une tâche donnée, il est recommandé d'utiliser des modules/bibliothèques/fonctions déjà existantes plutôt que de chercher à les reprogrammer de zéro(bien que cet exercice soit très instructif) car ces fonctions on souvent été déjà largement testées, et surtout cela permet \n",
    "d'envisage des développements/améliorations sur des bases établies.\n",
    "\n",
    "Par exemple, pour calculer un estimateur des MCO il existe énormément de modules disponible largement employés par la communauté. Nous allons en considérer deux associés à deux bibliothèques parmi les plus populaires:\n",
    "\n",
    "- [statsmodels](https://www.statsmodels.org/stable/index.html): orienté statistique au sens général.\n",
    "\n",
    "- [scikit-learn](https://scikit-learn.org/stable/): davantage apprentissage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**statsmodels**\n",
    "\n",
    "Une syntaxe de base est la suivante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  lwage   R-squared:                       0.280\n",
      "Model:                            OLS   Adj. R-squared:                  0.280\n",
      "Method:                 Least Squares   F-statistic:                     3602.\n",
      "Date:                Mon, 07 Feb 2022   Prob (F-statistic):               0.00\n",
      "Time:                        19:25:05   Log-Likelihood:                -39873.\n",
      "No. Observations:               46411   AIC:                         7.976e+04\n",
      "Df Residuals:                   46405   BIC:                         7.981e+04\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.0208      0.017     60.495      0.000       0.988       1.054\n",
      "education      0.1149      0.001    115.101      0.000       0.113       0.117\n",
      "female        -0.2629      0.005    -48.771      0.000      -0.274      -0.252\n",
      "black         -0.1104      0.008    -13.009      0.000      -0.127      -0.094\n",
      "exper          0.0369      0.001     44.842      0.000       0.035       0.039\n",
      "expersq       -0.0583      0.002    -34.281      0.000      -0.062      -0.055\n",
      "==============================================================================\n",
      "Omnibus:                    20304.171   Durbin-Watson:                   1.738\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           610974.968\n",
      "Skew:                          -1.498   Prob(JB):                         0.00\n",
      "Kurtosis:                      20.521   Cond. No.                         187.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "model = sm.OLS(dep_var, sm.add_constant(reg_var))\n",
    "results = model.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour avoir des écart-types estimés robustes à l'hétéroscédasticité vous pouvez faire:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  lwage   R-squared:                       0.280\n",
      "Model:                            OLS   Adj. R-squared:                  0.280\n",
      "Method:                 Least Squares   F-statistic:                     2869.\n",
      "Date:                Mon, 07 Feb 2022   Prob (F-statistic):               0.00\n",
      "Time:                        19:10:09   Log-Likelihood:                -39873.\n",
      "No. Observations:               46411   AIC:                         7.976e+04\n",
      "Df Residuals:                   46405   BIC:                         7.981e+04\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:                  HC0                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.0208      0.019     55.132      0.000       0.984       1.057\n",
      "education      0.1149      0.001    103.316      0.000       0.113       0.117\n",
      "female        -0.2629      0.005    -49.695      0.000      -0.273      -0.253\n",
      "black         -0.1104      0.008    -13.518      0.000      -0.126      -0.094\n",
      "exper          0.0369      0.001     40.408      0.000       0.035       0.039\n",
      "expersq       -0.0583      0.002    -29.069      0.000      -0.062      -0.054\n",
      "==============================================================================\n",
      "Omnibus:                    20304.171   Durbin-Watson:                   1.738\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           610974.968\n",
      "Skew:                          -1.498   Prob(JB):                         0.00\n",
      "Kurtosis:                      20.521   Cond. No.                         187.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are heteroscedasticity robust (HC0)\n"
     ]
    }
   ],
   "source": [
    "results2 = model.fit(cov_type='HC0')\n",
    "print(results2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remarques**\n",
    "\n",
    "- Comme pour le type d'écart-types plusieurs options sous forme d'arguments de la fonction existent. Pour plus de détails vous pouvez \n",
    "consulter la [documentation](https://www.statsmodels.org/dev/regression.html) et ou faire des rechercher(sur le web) en fonction de vos besoins.\n",
    "\n",
    "- L'option HC0 est une parmi d'autres disponibles pour les écart-types robustes à l'hétéroscédasticité, les autres étant 'HC1', 'HC2', 'HC3'. Pour de détails vous pouvez regarder la section 4.13 du [cours en pdf](https://www.ssc.wisc.edu/~bhansen/econometrics/Econometrics.pdf) de Bruce Hansen."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
